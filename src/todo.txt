Todo:

-> Generate Permutations                                [o]
-> Reduce Permutations                                  [o]
-> Label Permutations                                   [o]
-> Store permutation - label                            [z]
    * Is this needed ?
    - Not really, let's proceed
-> Do pre-computation                                   [ ]
-> Create a pure permutation labels
    + generator                                         [o]
    + storage                                           [o]
    + retrieval                                         [o]

-> Construct struct and graph           [ ]



Complexity problems:

-> get_code_by_moving_block (code, i, j, k)
    : Need to do in O(1) complexity, but how?
    : Need to be done in a very efficient serialized manner?

    : Precomputation:
        Suppose for [code][i][j] (code and block)
            -> We store min (code) which leads to optimal answer for all k
            to which we can tranpose this block
            -> If found use the value,
            -> If not found, calculate for all
        -> Will reduce complexity to O(n!*(n) + n!*n^2)

        -> This will require another level of abstraction


Stats:

size   pures    total_moves        average         time_taken                         distance_distribution            Memory Used
0		1		    0				 0
1		0		    0				 NaN
2		1		    1				 1
3		1		    2				 2
4		8		    17				 2.125                                              {3: 0, 2: 6}
5		36		    97				 2.6944444                                          {2: 10, 3: 24}
6		229		    732				 3.1965065                                          {4: 44, 3: 183}
7		1625	    6028			 3.7095385                                          {3: 471, 4: 1152}
8       13208       55299            4.186781       14s 256ms                           {3: 368, 5: 2835, 4: 10002}
9       120288      567119           4.7146764      2m 53s 855ms (12.19x)  -> 57s       {5: 85966, 4: 34320}
10      1214673     6277752          5.168265       38m 21s 924ms (19x)                 {4: 50665, 5: 908953, 6: 255052}      18 GB
                                                    23m init time!

most time is taken by precomputation!
> Post that it's very efficient
> We need to parallelize/optimize the precomputation part

Next options to work on:

-> Make code parallelizable
-> Make the pre-computation O(n!*n^2) time complexity

> Both of these will improve time complexity significantly
> 1 will give parallelization
> 2 will allow better theoretical complexity

> Doing 2 first will mean 1 can come without much rework
> If 1 is done first, after doing 2, we will need to integrate cleanly
> 1 is a bit of a mystery, will have to read and understand how to accomplish
> 1 is also the most important thing mentioned in the SoP
> Let's do 1 first.
    -> Meanwhile also think of ways to make 2 work cleanly

For size 9, init time taken (ms) = 150529, (s) = 150
For size 9, update_init_on_basis_of_previous time taken (ms) = 5822, (s) = 6
For size 9, process_pure_permutations: time taken (ms) = 2053, (s) = 2
============================= Post Optimization ================================
For size 9, init time taken (ms) = 2753, (s) = 2
For size 9, update_init_on_basis_of_previous time taken (ms) = 65, (s) = 0
For size 9, process_pure_permutations: time taken (ms) = 213129, (s) = 213
    set_initial_distance_for_pure_permutations, time taken: 205420 ms
    process_pure_permutations, time taken: 7709 ms

================================================================================
Problem:

-> Processing all permutations in sequence :
    > Practically slower
    > Theoretically same time complexity
    > Space Complexity?

-> Why is current version slower than sequential?
    > We are also processing copies!
        > We need to identify using reduced code
        > If reduced code is processed, don't process this one??