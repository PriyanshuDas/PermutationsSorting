Todo:

-> Generate Permutations                                [o]
-> Reduce Permutations                                  [o]
-> Label Permutations                                   [o]
-> Store permutation - label                            [z]
    * Is this needed ?
    - Not really, let's proceed
-> Do pre-computation                                   [ ]
-> Create a pure permutation labels
    + generator                                         [o]
    + storage                                           [o]
    + retrieval                                         [o]

-> Construct struct and graph           [ ]



Complexity problems:

-> get_code_by_moving_block (code, i, j, k)
    : Need to do in O(1) complexity, but how?
    : Need to be done in a very efficient serialized manner?

    : Precomputation:
        Suppose for [code][i][j] (code and block)
            -> We store min (code) which leads to optimal answer for all k
            to which we can tranpose this block
            -> If found use the value,
            -> If not found, calculate for all
        -> Will reduce complexity to O(n!*(n) + n!*n^2)

        -> This will require another level of abstraction


Stats:

size   pures    total_moves        average         time_taken                         distance_distribution            Memory Used
0		1		    0				 0
1		0		    0				 NaN
2		1		    1				 1
3		1		    2				 2
4		8		    17				 2.125                                              {3: 0, 2: 6}
5		36		    97				 2.6944444                                          {2: 10, 3: 24}
6		229		    732				 3.1965065                                          {4: 44, 3: 183}
7		1625	    6028			 3.7095385                                          {3: 471, 4: 1152}
8       13208       55299            4.186781       14s 256ms                           {3: 368, 5: 2835, 4: 10002}
9       120288      567119           4.7146764      2m 53s 855ms (12.19x)  -> 57s       {5: 85966, 4: 34320}
10      1214673     6277752          5.168265       38m 21s 924ms (19x)                 {4: 50665, 5: 908953, 6: 255052}      18 GB
                                                    23m init time!

most time is taken by precomputation!
> Post that it's very efficient
> We need to parallelize/optimize the precomputation part

Next options to work on:

-> Make code parallelizable
-> Make the pre-computation O(n!*n^2) time complexity

> Both of these will improve time complexity significantly
> 1 will give parallelization
> 2 will allow better theoretical complexity

> Doing 2 first will mean 1 can come without much rework
> If 1 is done first, after doing 2, we will need to integrate cleanly
> 1 is a bit of a mystery, will have to read and understand how to accomplish
> 1 is also the most important thing mentioned in the SoP
> Let's do 1 first.
    -> Meanwhile also think of ways to make 2 work cleanly

For size 9, init time taken (ms) = 150529, (s) = 150
For size 9, update_init_on_basis_of_previous time taken (ms) = 5822, (s) = 6
For size 9, process_pure_permutations: time taken (ms) = 2053, (s) = 2
============================= Post Optimization ================================
size: 0, total_pures: 1, total_distance: 0, average_distance: 0
	 distance_distribution: {0: 1}
size: 1, total_pures: 0, total_distance: 0, average_distance: NaN
	 distance_distribution: {}
size: 2, total_pures: 1, total_distance: 1, average_distance: 1
	 distance_distribution: {1: 1}
size: 3, total_pures: 1, total_distance: 2, average_distance: 2
	 distance_distribution: {2: 1}
size: 4, total_pures: 8, total_distance: 17, average_distance: 2.125
	 distance_distribution: {2: 7, 3: 1}
size: 5, total_pures: 36, total_distance: 97, average_distance: 2.6944444
	 distance_distribution: {2: 11, 3: 25}
size: 6, total_pures: 229, total_distance: 732, average_distance: 3.1965065
	 distance_distribution: {4: 45, 3: 184}
size: 7, total_pures: 1625, total_distance: 6028, average_distance: 3.7095385
	 distance_distribution: {3: 472, 4: 1153}
size: 8, total_pures: 13208, total_distance: 55299, average_distance: 4.186781
	 distance_distribution: {3: 369, 4: 10003, 5: 2836}
size: 9, total_pures: 120288, total_distance: 567119, average_distance: 4.7146764
	 distance_distribution: {4: 34321, 5: 85967}
size: 10, total_pures: 1214673, total_distance: 6277752, average_distance: 5.168265
	 distance_distribution: {6: 255053, 4: 50666, 5: 908954}
size: 11, total_pures: 13469897, total_distance: 76800553, average_distance: 5.7016435
	 distance_distribution: {5: 3966328, 7: 1, 4: 26251, 6: 9477317}

================================================================================
Problem:

-> Processing all permutations in sequence :
    > Practically slower
    > Theoretically same time complexity
    > Space Complexity?

-> Why is current version slower than sequential?
    > We are also processing copies!
        > We need to identify using reduced code
        > If reduced code is processed, don't process this one??