Todo:

-> Generate Permutations                                [o]
-> Reduce Permutations                                  [o]
-> Label Permutations                                   [o]
-> Store permutation - label                            [z]
    * Is this needed ?
    - Not really, let's proceed
-> Do pre-computation                                   [ ]
-> Create a pure permutation labels
    + generator                                         [o]
    + storage                                           [o]
    + retrieval                                         [o]

-> Construct struct and graph           [ ]



Complexity problems:

-> get_code_by_moving_block (code, i, j, k)
    : Need to do in O(1) complexity, but how?
    : Need to be done in a very efficient serialized manner?

    : Precomputation:
        Suppose for [code][i][j] (code and block)
            -> We store min (code) which leads to optimal answer for all k
            to which we can tranpose this block
            -> If found use the value,
            -> If not found, calculate for all
        -> Will reduce complexity to O(n!*(n) + n!*n^2)

        -> This will require another level of abstraction


Stats:

size   pures    total_moves        average         time_taken                         distance_distribution            Memory Used
0		1		    0				 0
1		0		    0				 NaN
2		1		    1				 1
3		1		    2				 2
4		8		    17				 2.125                                              {3: 0, 2: 6}
5		36		    97				 2.6944444                                          {2: 10, 3: 24}
6		229		    732				 3.1965065                                          {4: 44, 3: 183}
7		1625	    6028			 3.7095385                                          {3: 471, 4: 1152}
8       13208       55299            4.186781       14s 256ms                           {3: 368, 5: 2835, 4: 10002}
9       120288      567119           4.7146764      2m 53s 855ms (12.19x)  -> 57s       {5: 85966, 4: 34320}
10      1214673     6277752          5.168265       38m 21s 924ms (19x)                 {4: 50665, 5: 908953, 6: 255052}      18 GB


most time is taken by precomputation!
> Post that it's very efficient
> We need to parallelize/optimize the precomputation part

Next options to work on:

-> Make code parallelizable
-> Make the pre-computation O(n!*n^2) time complexity

> Both of these will improve time complexity significantly
> 1 will give parallelization
> 2 will allow better theoretical complexity

> Doing 2 first will mean 1 can come without much rework
> If 1 is done first, after doing 2, we will need to integrate cleanly
> 1 is a bit of a mystery, will have to read and understand how to accomplish
> 1 is also the most important thing mentioned in the SoP
> Let's do 1 first.
    -> Meanwhile also think of ways to make 2 work cleanly

For size 9, init time taken (ms) = 150529, (s) = 150
For size 9, update_init_on_basis_of_previous time taken (ms) = 5822, (s) = 6
For size 9, process_pure_permutations: time taken (ms) = 2053, (s) = 2


5s [concurrent] for 10
46s [non-concurrent] for 10

=> 90% reduction in time!


init_next_step took : 28 ms, 0 s
init_visited took : 10356 ms, 10 s
    => Parallelizing
    => Post parallelizing : init_visited took : 960 ms, 0 s

init_distance took : 26 ms, 0 s
adjacency_calculator::init() took : 1041 ms, 1 s

reduced_code took : 5034 ms, 5 s
    => Parallelising
    => reduced to reduced_code took : 532 ms, 0 s

block_slide_reduction_memo took : 11914 ms, 12 s
init_pure_permutations took : 33 ms, 0 s